### Semantic Vector Search Engine

A fully modular semantic search system built using:

1) Python
2) Sentence-Transformers (all-MiniLM-L6-v2)
3) FastAPI
4) Custom caching system
5) Cosine-similarity ranking

## ğŸ“ Project Structure

```text
project/
â”‚
â”œâ”€â”€ data/               # ignored in Git (contains docs)
â”‚   â””â”€â”€ docs/           # dataset text files
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embedder.py         # text cleaning + hashing utilities
â”‚   â”œâ”€â”€ embedding_model.py  # loads embedding model + computes embeddings
â”‚   â”œâ”€â”€ cache_manager.py    # stores & retrieves embeddings using JSON cache
â”‚   â”œâ”€â”€ search_engine.py    # performs semantic search + ranking
â”‚   â”œâ”€â”€ api.py              # FastAPI /search endpoint
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```


### How Caching Works

Every document is cleaned, hashed, and checked against a JSON cache:
{
  "doc_id": "doc_001",
  "embedding": [...],
  "hash": "sha256_hash_of_text",
  "updated_at": 1732164210.12
}

### When a document loads:

If hash matches â†’ reuse stored embedding
If hash changed â†’ re-embed and update cache

This makes the system fast and avoids recomputing 200+ embeddings

### Search Pipeline

When a user sends a query:

1) Query is embedded using all-MiniLM-L6-v2
2) All document embeddings are loaded (from cache or computed)
3) Cosine similarity is calculated between query + each doc
4) Top-K ranked documents are returned

Example API input:
{
  "query": "space shuttle engineering",
  "top_k": 5
}

Example API output:
{
  "results": [
    ["doc_0153", 0.42],
    ["doc_0059", 0.40],
    ["doc_0049", 0.28]
  ]
}

### Run the API
cd src
uvicorn api:app --reload --host 127.0.0.1 --port 8000

Visit:

ğŸ“Œ http://127.0.0.1:8000/docs
to test the /search endpoint.


### Design Choices

Sentence-Transformers chosen for fast CPU-friendly embeddings
JSON cache for transparency & simplicity
Custom cosine-similarity search (easy to understand & debug)
Modular src/ layout enables upgrading to:
    FAISS index
    Streamlit UI
    Batch embedding
    Query expansion



